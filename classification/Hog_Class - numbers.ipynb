{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04a0dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Final\n",
    "\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "\n",
    "#import commonfunctions as cf\n",
    "from skimage.feature import hog\n",
    "import skimage.io as io\n",
    "import cv2\n",
    "import pickle\n",
    "import joblib\n",
    "import skimage.io as io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75e3e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_0_dataset = r'0_1_DataSets/0'\n",
    "path_to_1_dataset = r'0_1_DataSets/1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2281e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(img): \n",
    "    img=cv2.resize(img,(64,64))\n",
    "    fd, hog_image = hog(\n",
    "        img,\n",
    "        pixels_per_cell=(2, 2),\n",
    "        cells_per_block=(2, 2),\n",
    "        visualize=True,        \n",
    "    )\n",
    "    return fd,hog_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "430e9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    features = []\n",
    "    labels = []\n",
    "    img_filenames_0 = os.listdir(path_to_0_dataset)\n",
    "    img_filenames_1 = os.listdir(path_to_1_dataset)\n",
    "\n",
    "\n",
    "    for i, fn in enumerate(img_filenames_0):\n",
    "        if fn.split('.')[-1] != 'png' and fn.split('.')[-1]!='jpg':\n",
    "            continue\n",
    "\n",
    "        label = 0\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_0_dataset, fn)\n",
    "        img = io.imread(path)\n",
    "        fd,img = extract_hog_features(img)\n",
    "        fd=np.append(fd,label)\n",
    "        features.append(fd)\n",
    "        \n",
    "        # show an update every 1,000 images\n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames_0)))\n",
    "    print(\"0 dataset processing done\")\n",
    "    for i, fn in enumerate(img_filenames_1):\n",
    "        if fn.split('.')[-1] != 'png' and fn.split('.')[-1]!='jpg':\n",
    "            continue\n",
    "\n",
    "        label = 1\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_1_dataset, fn)\n",
    "        img = io.imread(path)\n",
    "        fd,img = extract_hog_features(img)\n",
    "        fd=np.append(fd,label)\n",
    "        features.append(fd)\n",
    "        \n",
    "        # show an update every 1,000 images\n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames_1)))     \n",
    "    print(\"1 dataset processing done\")   \n",
    "        \n",
    "    return features, labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1adad80d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 10/188\n",
      "[INFO] processed 20/188\n",
      "[INFO] processed 30/188\n",
      "[INFO] processed 40/188\n",
      "[INFO] processed 50/188\n",
      "[INFO] processed 60/188\n",
      "[INFO] processed 70/188\n",
      "[INFO] processed 80/188\n",
      "[INFO] processed 90/188\n",
      "[INFO] processed 100/188\n",
      "[INFO] processed 110/188\n",
      "[INFO] processed 120/188\n",
      "[INFO] processed 130/188\n",
      "[INFO] processed 140/188\n",
      "[INFO] processed 150/188\n",
      "[INFO] processed 160/188\n",
      "[INFO] processed 170/188\n",
      "[INFO] processed 180/188\n",
      "0 dataset processing done\n",
      "[INFO] processed 10/180\n",
      "[INFO] processed 20/180\n",
      "[INFO] processed 30/180\n",
      "[INFO] processed 40/180\n",
      "[INFO] processed 50/180\n",
      "[INFO] processed 60/180\n",
      "[INFO] processed 70/180\n",
      "[INFO] processed 80/180\n",
      "[INFO] processed 90/180\n",
      "[INFO] processed 100/180\n",
      "[INFO] processed 110/180\n",
      "[INFO] processed 120/180\n",
      "[INFO] processed 130/180\n",
      "[INFO] processed 140/180\n",
      "[INFO] processed 150/180\n",
      "[INFO] processed 160/180\n",
      "[INFO] processed 170/180\n",
      "1 dataset processing done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "features,labels = load_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6fc8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(features,name):\n",
    "  with open(name, 'wb') as file:\n",
    "     pickle.dump(features, file)\n",
    "\n",
    "save_model(features,\"numbers_model2.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9575a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_string_map = dict(zip(map(tuple, features), labels))\n",
    "# save_model(feature_string_map,\"letters_map.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2ca48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(name):\n",
    "  with open(name, 'rb') as file:\n",
    "      loaded_array_list = pickle.load(file)\n",
    "      return loaded_array_list\n",
    "features = load_model(\"numbers_model2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7ed9b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(feat1: np.ndarray, feat2: np.ndarray) -> float:\n",
    "\n",
    "    return np.mean((feat1 - feat2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "625927fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def natural_sort_key(s):\n",
    "    \"\"\"Key function for natural sorting.\"\"\"\n",
    "    import re\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "output_file_path = 'results.txt'\n",
    "path_to_testset = r'testset'\n",
    "filenames = sorted(os.listdir(path_to_testset), key=natural_sort_key)\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for i, fn in enumerate(filenames):\n",
    "        if fn.split('.')[-1] != 'png' and fn.split('.')[-1]!='jpg':\n",
    "            continue\n",
    "        image=io.imread(os.path.join(path_to_testset, fn))\n",
    "        feature_extract,_=extract_hog_features(image)\n",
    "        \n",
    "        distances: float = [\n",
    "        calculate_distance(feature_extract, src_feat[:-1]) \n",
    "        for src_feat in features\n",
    "        ]\n",
    "        min_distance_index = np.argmin(distances)\n",
    "        # k = 5\n",
    "        # min_distance_indices = np.argpartition(distances, k)[:k]\n",
    "        # result = []\n",
    "        # for i, idx in enumerate(min_distance_indices):\n",
    "        #     result.append(get_char_from_digit(features[idx][-1]))\n",
    "        result=features[min_distance_index][-1]\n",
    "        print(result)\n",
    "        #output_file.write(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
