{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier  # MLP is an NN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_a_dataset = r'letters_data_set/A'\n",
    "path_to_b_dataset = r'letters_data_set/B'\n",
    "path_to_c_dataset = r'letters_data_set/C'\n",
    "path_to_d_dataset = r'letters_data_set/D'\n",
    "path_to_e_dataset = r'letters_data_set/E'\n",
    "KNN = KNeighborsClassifier(n_neighbors=15,weights='distance')\n",
    "random_seed=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(img):\n",
    "    \n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    win_size = (32, 32)\n",
    "    cell_size = (4, 4)\n",
    "    block_size_in_cells = (2, 2)\n",
    "    \n",
    "    block_size = (block_size_in_cells[1] * cell_size[1], block_size_in_cells[0] * cell_size[0])\n",
    "    block_stride = (cell_size[1], cell_size[0])\n",
    "    nbins = 12 \n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "    h = hog.compute(img)\n",
    "    return h.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    features = []\n",
    "    labels = []\n",
    "    img_filenames_a = os.listdir(path_to_a_dataset)\n",
    "    img_filenames_b = os.listdir(path_to_b_dataset)\n",
    "    img_filenames_c = os.listdir(path_to_c_dataset)\n",
    "    img_filenames_d = os.listdir(path_to_d_dataset)\n",
    "    img_filenames_e = os.listdir(path_to_e_dataset)\n",
    "\n",
    "\n",
    "    for i, fn in enumerate(img_filenames_a):\n",
    "        if fn.split('.')[-1] != 'png' and fn.split('.')[-1]!='jpg':\n",
    "            continue\n",
    "\n",
    "        label = 'A'\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_a_dataset, fn)\n",
    "        img = cv2.imread(path)\n",
    "        \n",
    "        features.append(extract_hog_features(img))\n",
    "        \n",
    "        # show an update every 10 images\n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames_a)))\n",
    "    print(\"A dataset processing done\")\n",
    "    for i, fn in enumerate(img_filenames_b):\n",
    "        if fn.split('.')[-1] != 'png' and fn.split('.')[-1]!='jpg':\n",
    "            continue\n",
    "\n",
    "        label = 'B'\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_b_dataset, fn)\n",
    "        img = cv2.imread(path)\n",
    "        features.append(extract_hog_features(img))\n",
    "        \n",
    "        # show an update every 10 images\n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames_b)))     \n",
    "    print(\"B dataset processing done\")   \n",
    "    \n",
    "    for i, fn in enumerate(img_filenames_c):\n",
    "        if fn.split('.')[-1] != 'png' and fn.split('.')[-1]!='jpg':\n",
    "            continue\n",
    "\n",
    "        label = 'C'\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_c_dataset, fn)\n",
    "        img = cv2.imread(path)\n",
    "        features.append(extract_hog_features(img))\n",
    "        \n",
    "        # show an update every 10 images\n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames_c)))     \n",
    "    print(\"C dataset processing done\")   \n",
    "    \n",
    "    for i, fn in enumerate(img_filenames_d):\n",
    "        if fn.split('.')[-1] != 'png' and fn.split('.')[-1]!='jpg':\n",
    "            continue\n",
    "\n",
    "        label = 'D'\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_d_dataset, fn)\n",
    "        img = cv2.imread(path)\n",
    "        features.append(extract_hog_features(img))\n",
    "        \n",
    "        # show an update every 10 images\n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames_d)))     \n",
    "    print(\"D dataset processing done\")   \n",
    "    \n",
    "    # for i, fn in enumerate(img_filenames_e):\n",
    "    #     if fn.split('.')[-1] != 'png' and fn.split('.')[-1]!='jpg':\n",
    "    #         continue\n",
    "\n",
    "    #     label = 'E'\n",
    "    #     labels.append(label)\n",
    "\n",
    "    #     path = os.path.join(path_to_e_dataset, fn)\n",
    "    #     img = cv2.imread(path)\n",
    "    #     features.append(extract_hog_features(img))\n",
    "        \n",
    "    #     # show an update every 10 images\n",
    "    #     if i > 0 and i % 10 == 0:\n",
    "    #         print(\"[INFO] processed {}/{}\".format(i, len(img_filenames_e)))     \n",
    "    # print(\"E dataset processing done\")   \n",
    "    \n",
    "\n",
    "    return features, labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    # Load dataset with extracted features\n",
    "    print('Loading dataset. This will take time ...')\n",
    "    features, labels = load_dataset()\n",
    "    print('Finished loading dataset.')\n",
    "    print(len(labels))\n",
    "\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "        features, labels, test_size=0.2, random_state=random_seed)\n",
    "    \n",
    "    #print(labels)\n",
    "       \n",
    "    KNN.fit(train_features, train_labels)\n",
    "        \n",
    "    \n",
    "    accuracy = KNN.score(test_features, test_labels)\n",
    "        \n",
    "    print('accuracy: ', accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset. This will take time ...\n",
      "[INFO] processed 10/45\n",
      "[INFO] processed 20/45\n",
      "[INFO] processed 30/45\n",
      "[INFO] processed 40/45\n",
      "A dataset processing done\n",
      "[INFO] processed 10/45\n",
      "[INFO] processed 20/45\n",
      "[INFO] processed 30/45\n",
      "[INFO] processed 40/45\n",
      "B dataset processing done\n",
      "[INFO] processed 10/45\n",
      "[INFO] processed 20/45\n",
      "[INFO] processed 30/45\n",
      "[INFO] processed 40/45\n",
      "C dataset processing done\n",
      "[INFO] processed 10/45\n",
      "[INFO] processed 20/45\n",
      "[INFO] processed 30/45\n",
      "[INFO] processed 40/45\n",
      "D dataset processing done\n",
      "Finished loading dataset.\n",
      "180\n",
      "accuracy:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n",
      "test0.png A\n",
      "\n",
      "['A']\n",
      "test1.png A\n",
      "\n",
      "['A']\n",
      "test2.png A\n",
      "\n",
      "['C']\n",
      "test3.png A\n",
      "\n",
      "['B']\n",
      "test4.png A\n",
      "\n",
      "['D']\n",
      "test5.png A\n",
      "\n",
      "['D']\n",
      "test6.png A\n",
      "\n",
      "['B']\n",
      "test7.png A\n",
      "\n",
      "['C']\n",
      "test8.png A\n",
      "\n",
      "['C']\n",
      "test192.png A\n",
      "\n",
      "['B']\n",
      "test193.png A\n",
      "\n",
      "['B']\n",
      "test194.png A\n",
      "\n",
      "['B']\n",
      "test195.png A\n",
      "\n",
      "['C']\n",
      "test196.png A\n",
      "\n",
      "['C']\n",
      "test197.png A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "letters=['A','B','C','D','E','F']\n",
    "def natural_sort_key(s):\n",
    "    \"\"\"Key function for natural sorting.\"\"\"\n",
    "    import re\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "output_file_path = 'results.txt'\n",
    "path_to_testset = r'testset3'\n",
    "filenames = sorted(os.listdir(path_to_testset), key=natural_sort_key)\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for i, fn in enumerate(filenames):\n",
    "        if fn.split('.')[-1] != 'png' and fn.split('.')[-1]!='jpg':\n",
    "            continue\n",
    "        features = extract_hog_features(cv2.imread(os.path.join(path_to_testset, fn)))\n",
    "        pred = KNN.predict([features])\n",
    "        result = f\"{fn} {letters[np.argmax(pred)]}\\n\"\n",
    "        print(pred)\n",
    "        print(result)  \n",
    "        output_file.write(result)\n",
    "    \n",
    "# features=extract_hog_features(cv2.imread('test.png'))\n",
    "# pred=KNN.predict_proba([features])\n",
    "# print(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
