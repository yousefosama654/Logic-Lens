{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier  # MLP is an NN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_a_dataset = r'letters_data_set/A'\n",
    "path_to_b_dataset = r'letters_data_set/B'\n",
    "path_to_c_dataset = r'letters_data_set/C'\n",
    "path_to_d_dataset = r'letters_data_set/D'\n",
    "path_to_e_dataset = r'letters_data_set/E'\n",
    "path_to_f_dataset = r'letters_data_set/F'\n",
    "KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "random_seed=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(img):\n",
    "    \n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    win_size = (32, 32)\n",
    "    cell_size = (4, 4)\n",
    "    block_size_in_cells = (2, 2)\n",
    "    \n",
    "    block_size = (block_size_in_cells[1] * cell_size[1], block_size_in_cells[0] * cell_size[0])\n",
    "    block_stride = (cell_size[1], cell_size[0])\n",
    "    nbins = 9  \n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins,2)\n",
    "    h = hog.compute(img)\n",
    "    return h.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    features = []\n",
    "    labels = []\n",
    "    img_filenames_a = os.listdir(path_to_a_dataset)\n",
    "    img_filenames_b = os.listdir(path_to_b_dataset)\n",
    "    img_filenames_c = os.listdir(path_to_c_dataset)\n",
    "    img_filenames_d = os.listdir(path_to_d_dataset)\n",
    "    img_filenames_e = os.listdir(path_to_e_dataset)\n",
    "    img_filenames_f = os.listdir(path_to_f_dataset)\n",
    "\n",
    "\n",
    "    for i, fn in enumerate(img_filenames_a):\n",
    "        if fn.split('.')[-1] != 'png':\n",
    "            continue\n",
    "\n",
    "        label = 'A'\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_a_dataset, fn)\n",
    "        img = cv2.imread(path)\n",
    "        features.append(extract_hog_features(img))\n",
    "        \n",
    "        # show an update every 10 images\n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames_a)))\n",
    "    print(\"A dataset processing done\")\n",
    "    for i, fn in enumerate(img_filenames_b):\n",
    "        if fn.split('.')[-1] != 'png':\n",
    "            continue\n",
    "\n",
    "        label = 'B'\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_b_dataset, fn)\n",
    "        img = cv2.imread(path)\n",
    "        features.append(extract_hog_features(img))\n",
    "        \n",
    "        # show an update every 10 images\n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames_b)))     \n",
    "    print(\"B dataset processing done\")   \n",
    "    \n",
    "    for i, fn in enumerate(img_filenames_c):\n",
    "        if fn.split('.')[-1] != 'png':\n",
    "            continue\n",
    "\n",
    "        label = 'C'\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_c_dataset, fn)\n",
    "        img = cv2.imread(path)\n",
    "        features.append(extract_hog_features(img))\n",
    "        \n",
    "        # show an update every 10 images\n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames_c)))     \n",
    "    print(\"C dataset processing done\")   \n",
    "    \n",
    "    for i, fn in enumerate(img_filenames_d):\n",
    "        if fn.split('.')[-1] != 'png':\n",
    "            continue\n",
    "\n",
    "        label = 'D'\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_d_dataset, fn)\n",
    "        img = cv2.imread(path)\n",
    "        features.append(extract_hog_features(img))\n",
    "        \n",
    "        # show an update every 10 images\n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames_d)))     \n",
    "    print(\"D dataset processing done\")   \n",
    "    \n",
    "    for i, fn in enumerate(img_filenames_e):\n",
    "        if fn.split('.')[-1] != 'png':\n",
    "            continue\n",
    "\n",
    "        label = 'E'\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_e_dataset, fn)\n",
    "        img = cv2.imread(path)\n",
    "        features.append(extract_hog_features(img))\n",
    "        \n",
    "        # show an update every 10 images\n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames_e)))     \n",
    "    print(\"E dataset processing done\")   \n",
    "    \n",
    "    for i, fn in enumerate(img_filenames_f):\n",
    "        if fn.split('.')[-1] != 'png':\n",
    "            continue\n",
    "\n",
    "        label = 'F'\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_f_dataset, fn)\n",
    "        img = cv2.imread(path)\n",
    "        features.append(extract_hog_features(img))\n",
    "        \n",
    "        # show an update every 10 images\n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames_f)))     \n",
    "    print(\"F dataset processing done\")   \n",
    "        \n",
    "    return features, labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    # Load dataset with extracted features\n",
    "    print('Loading dataset. This will take time ...')\n",
    "    features, labels = load_dataset()\n",
    "    print('Finished loading dataset.')\n",
    "    \n",
    "\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "        features, labels, test_size=0.3, random_state=random_seed)\n",
    "    \n",
    "    #print(labels)\n",
    "       \n",
    "    KNN.fit(train_features, train_labels)\n",
    "        \n",
    "    \n",
    "    accuracy = KNN.score(test_features, test_labels)\n",
    "        \n",
    "    print('accuracy: ', accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset. This will take time ...\n",
      "[INFO] processed 10/76\n",
      "[INFO] processed 20/76\n",
      "[INFO] processed 30/76\n",
      "[INFO] processed 40/76\n",
      "[INFO] processed 50/76\n",
      "[INFO] processed 60/76\n",
      "[INFO] processed 70/76\n",
      "A dataset processing done\n",
      "[INFO] processed 10/65\n",
      "[INFO] processed 20/65\n",
      "[INFO] processed 30/65\n",
      "[INFO] processed 40/65\n",
      "[INFO] processed 50/65\n",
      "[INFO] processed 60/65\n",
      "B dataset processing done\n",
      "[INFO] processed 10/79\n",
      "[INFO] processed 20/79\n",
      "[INFO] processed 30/79\n",
      "[INFO] processed 40/79\n",
      "[INFO] processed 50/79\n",
      "[INFO] processed 60/79\n",
      "[INFO] processed 70/79\n",
      "C dataset processing done\n",
      "[INFO] processed 10/76\n",
      "[INFO] processed 20/76\n",
      "[INFO] processed 30/76\n",
      "[INFO] processed 40/76\n",
      "[INFO] processed 50/76\n",
      "[INFO] processed 60/76\n",
      "[INFO] processed 70/76\n",
      "D dataset processing done\n",
      "[INFO] processed 10/70\n",
      "[INFO] processed 20/70\n",
      "[INFO] processed 30/70\n",
      "[INFO] processed 40/70\n",
      "[INFO] processed 50/70\n",
      "[INFO] processed 60/70\n",
      "E dataset processing done\n",
      "[INFO] processed 10/78\n",
      "[INFO] processed 20/78\n",
      "[INFO] processed 30/78\n",
      "[INFO] processed 40/78\n",
      "[INFO] processed 50/78\n",
      "[INFO] processed 60/78\n",
      "[INFO] processed 70/78\n",
      "F dataset processing done\n",
      "Finished loading dataset.\n",
      "accuracy:  89.55223880597015 %\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test2.png B\n",
      "\n",
      "test5.png B\n",
      "\n",
      "test6.png D\n",
      "\n",
      "test7.png B\n",
      "\n",
      "test8.png B\n",
      "\n",
      "test9.png B\n",
      "\n",
      "test10.png B\n",
      "\n",
      "test11.png B\n",
      "\n",
      "test16.png E\n",
      "\n",
      "test17.png B\n",
      "\n",
      "test18.png B\n",
      "\n",
      "test19.png B\n",
      "\n",
      "test20.png D\n",
      "\n",
      "test22.png B\n",
      "\n",
      "test23.png B\n",
      "\n",
      "test24.png B\n",
      "\n",
      "test25.png B\n",
      "\n",
      "test26.png B\n",
      "\n",
      "test27.png E\n",
      "\n",
      "test29.png D\n",
      "\n",
      "test30.png E\n",
      "\n",
      "test33.png B\n",
      "\n",
      "test34.png B\n",
      "\n",
      "test35.png B\n",
      "\n",
      "test38.png B\n",
      "\n",
      "test39.png B\n",
      "\n",
      "test40.png D\n",
      "\n",
      "test41.png B\n",
      "\n",
      "test42.png B\n",
      "\n",
      "test43.png E\n",
      "\n",
      "test49.png E\n",
      "\n",
      "test50.png E\n",
      "\n",
      "test51.png B\n",
      "\n",
      "test53.png E\n",
      "\n",
      "test55.png B\n",
      "\n",
      "test61.png B\n",
      "\n",
      "test62.png E\n",
      "\n",
      "test63.png B\n",
      "\n",
      "test64.png E\n",
      "\n",
      "test65.png B\n",
      "\n",
      "test66.png B\n",
      "\n",
      "test76.png B\n",
      "\n",
      "test77.png B\n",
      "\n",
      "test78.png E\n",
      "\n",
      "test79.png D\n",
      "\n",
      "test80.png B\n",
      "\n",
      "test81.png E\n",
      "\n",
      "test82.png B\n",
      "\n",
      "test83.png B\n",
      "\n",
      "test84.png B\n",
      "\n",
      "test85.png B\n",
      "\n",
      "test86.png E\n",
      "\n",
      "test92.png B\n",
      "\n",
      "test93.png B\n",
      "\n",
      "test94.png B\n",
      "\n",
      "test95.png B\n",
      "\n",
      "test96.png E\n",
      "\n",
      "test97.png B\n",
      "\n",
      "test98.png E\n",
      "\n",
      "test100.png E\n",
      "\n",
      "test102.png A\n",
      "\n",
      "test103.png D\n",
      "\n",
      "test104.png E\n",
      "\n",
      "test106.png D\n",
      "\n",
      "test107.png B\n",
      "\n",
      "test108.png B\n",
      "\n",
      "test111.png B\n",
      "\n",
      "test113.png B\n",
      "\n",
      "test114.png B\n",
      "\n",
      "test117.png B\n",
      "\n",
      "test118.png B\n",
      "\n",
      "test119.png C\n",
      "\n",
      "test120.png D\n",
      "\n",
      "test121.png E\n",
      "\n",
      "test123.png E\n",
      "\n",
      "test124.png B\n",
      "\n",
      "test125.png B\n",
      "\n",
      "test126.png C\n",
      "\n",
      "test127.png B\n",
      "\n",
      "test128.png B\n",
      "\n",
      "test129.png B\n",
      "\n",
      "test131.png D\n",
      "\n",
      "test132.png B\n",
      "\n",
      "test133.png B\n",
      "\n",
      "test134.png B\n",
      "\n",
      "test135.png E\n",
      "\n",
      "test136.png E\n",
      "\n",
      "test137.png B\n",
      "\n",
      "test138.png D\n",
      "\n",
      "test139.png B\n",
      "\n",
      "test140.png D\n",
      "\n",
      "test141.png B\n",
      "\n",
      "test142.png B\n",
      "\n",
      "test143.png B\n",
      "\n",
      "test144.png B\n",
      "\n",
      "test146.png B\n",
      "\n",
      "test149.png B\n",
      "\n",
      "test150.png B\n",
      "\n",
      "test151.png B\n",
      "\n",
      "test152.png E\n",
      "\n",
      "test153.png E\n",
      "\n",
      "test154.png B\n",
      "\n",
      "test155.png B\n",
      "\n",
      "test156.png B\n",
      "\n",
      "test157.png B\n",
      "\n",
      "test158.png B\n",
      "\n",
      "test159.png B\n",
      "\n",
      "test160.png B\n",
      "\n",
      "test163.png B\n",
      "\n",
      "test164.png B\n",
      "\n",
      "test165.png B\n",
      "\n",
      "test166.png B\n",
      "\n",
      "test167.png D\n",
      "\n",
      "test168.png B\n",
      "\n",
      "test169.png D\n",
      "\n",
      "test170.png B\n",
      "\n",
      "test171.png B\n",
      "\n",
      "test172.png E\n",
      "\n",
      "test173.png E\n",
      "\n",
      "test175.png B\n",
      "\n",
      "test176.png D\n",
      "\n",
      "test177.png B\n",
      "\n",
      "test179.png B\n",
      "\n",
      "test180.png D\n",
      "\n",
      "test181.png B\n",
      "\n"
     ]
    }
   ],
   "source": [
    "letters=['A','B','C','D','E','F']\n",
    "def natural_sort_key(s):\n",
    "    \"\"\"Key function for natural sorting.\"\"\"\n",
    "    import re\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "output_file_path = 'results.txt'\n",
    "path_to_testset = r'testset'\n",
    "filenames = sorted(os.listdir(path_to_testset), key=natural_sort_key)\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for i, fn in enumerate(filenames):\n",
    "        if fn.split('.')[-1] != 'png':\n",
    "            continue\n",
    "        features = extract_hog_features(cv2.imread(os.path.join(path_to_testset, fn)))\n",
    "        pred = KNN.predict_proba([features])\n",
    "        result = f\"{fn} {letters[np.argmax(pred)]}\\n\"\n",
    "        print(result)  \n",
    "        output_file.write(result)\n",
    "    \n",
    "# features=extract_hog_features(cv2.imread('test.png'))\n",
    "# pred=KNN.predict_proba([features])\n",
    "# print(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
