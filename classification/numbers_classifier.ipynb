{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier  # MLP is an NN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_0_dataset = r'0_1_DataSets/0'\n",
    "path_to_1_dataset = r'0_1_DataSets/1'\n",
    "KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "random_seed=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(img):\n",
    "    \n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    win_size = (32, 32)\n",
    "    cell_size = (4, 4)\n",
    "    block_size_in_cells = (2, 2)\n",
    "    \n",
    "    block_size = (block_size_in_cells[1] * cell_size[1], block_size_in_cells[0] * cell_size[0])\n",
    "    block_stride = (cell_size[1], cell_size[0])\n",
    "    nbins = 9  \n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins,2)\n",
    "    h = hog.compute(img)\n",
    "    return h.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    features = []\n",
    "    labels = []\n",
    "    img_filenames_0 = os.listdir(path_to_0_dataset)\n",
    "    img_filenames_1 = os.listdir(path_to_1_dataset)\n",
    "\n",
    "\n",
    "    for i, fn in enumerate(img_filenames_0):\n",
    "        if fn.split('.')[-1] != 'png':\n",
    "            continue\n",
    "\n",
    "        label = '0'\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_0_dataset, fn)\n",
    "        img = cv2.imread(path)\n",
    "        features.append(extract_hog_features(img))\n",
    "        \n",
    "        # show an update every 1,000 images\n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames_0)))\n",
    "    print(\"0 dataset processing done\")\n",
    "    for i, fn in enumerate(img_filenames_1):\n",
    "        if fn.split('.')[-1] != 'png':\n",
    "            continue\n",
    "\n",
    "        label = '1'\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_1_dataset, fn)\n",
    "        img = cv2.imread(path)\n",
    "        features.append(extract_hog_features(img))\n",
    "        \n",
    "        # show an update every 1,000 images\n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames_1)))     \n",
    "    print(\"1 dataset processing done\")   \n",
    "        \n",
    "    return features, labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    # Load dataset with extracted features\n",
    "    print('Loading dataset. This will take time ...')\n",
    "    features, labels = load_dataset()\n",
    "    print('Finished loading dataset.')\n",
    "    \n",
    "\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "        features, labels, test_size=0.3, random_state=random_seed)\n",
    "    \n",
    "    #print(labels)\n",
    "       \n",
    "    KNN.fit(train_features, train_labels)\n",
    "        \n",
    "    \n",
    "    accuracy = KNN.score(test_features, test_labels)\n",
    "        \n",
    "    print('accuracy: ', accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset. This will take time ...\n",
      "[INFO] processed 10/74\n",
      "[INFO] processed 20/74\n",
      "[INFO] processed 30/74\n",
      "[INFO] processed 40/74\n",
      "[INFO] processed 50/74\n",
      "[INFO] processed 60/74\n",
      "0 dataset processing done\n",
      "[INFO] processed 10/79\n",
      "[INFO] processed 20/79\n",
      "[INFO] processed 30/79\n",
      "[INFO] processed 40/79\n",
      "[INFO] processed 50/79\n",
      "[INFO] processed 60/79\n",
      "[INFO] processed 70/79\n",
      "1 dataset processing done\n",
      "Finished loading dataset.\n",
      "accuracy:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test2.png 1\n",
      "\n",
      "test5.png 1\n",
      "\n",
      "test6.png 0\n",
      "\n",
      "test7.png 1\n",
      "\n",
      "test8.png 0\n",
      "\n",
      "test9.png 0\n",
      "\n",
      "test10.png 0\n",
      "\n",
      "test11.png 0\n",
      "\n",
      "test16.png 1\n",
      "\n",
      "test17.png 0\n",
      "\n",
      "test18.png 1\n",
      "\n",
      "test19.png 1\n",
      "\n",
      "test20.png 1\n",
      "\n",
      "test22.png 0\n",
      "\n",
      "test23.png 0\n",
      "\n",
      "test24.png 1\n",
      "\n",
      "test25.png 1\n",
      "\n",
      "test26.png 0\n",
      "\n",
      "test27.png 1\n",
      "\n",
      "test29.png 1\n",
      "\n",
      "test30.png 1\n",
      "\n",
      "test33.png 0\n",
      "\n",
      "test34.png 1\n",
      "\n",
      "test35.png 0\n",
      "\n",
      "test38.png 1\n",
      "\n",
      "test39.png 0\n",
      "\n",
      "test40.png 0\n",
      "\n",
      "test41.png 0\n",
      "\n",
      "test42.png 1\n",
      "\n",
      "test43.png 1\n",
      "\n",
      "test49.png 1\n",
      "\n",
      "test50.png 1\n",
      "\n",
      "test51.png 1\n",
      "\n",
      "test53.png 1\n",
      "\n",
      "test55.png 0\n",
      "\n",
      "test61.png 0\n",
      "\n",
      "test62.png 1\n",
      "\n",
      "test63.png 0\n",
      "\n",
      "test64.png 1\n",
      "\n",
      "test65.png 0\n",
      "\n",
      "test66.png 0\n",
      "\n",
      "test76.png 1\n",
      "\n",
      "test77.png 0\n",
      "\n",
      "test78.png 1\n",
      "\n",
      "test79.png 0\n",
      "\n",
      "test80.png 0\n",
      "\n",
      "test81.png 1\n",
      "\n",
      "test82.png 0\n",
      "\n",
      "test83.png 0\n",
      "\n",
      "test84.png 0\n",
      "\n",
      "test85.png 0\n",
      "\n",
      "test86.png 1\n",
      "\n",
      "test92.png 0\n",
      "\n",
      "test93.png 0\n",
      "\n",
      "test94.png 0\n",
      "\n",
      "test95.png 0\n",
      "\n",
      "test96.png 1\n",
      "\n",
      "test97.png 0\n",
      "\n",
      "test98.png 1\n",
      "\n",
      "test100.png 1\n",
      "\n",
      "test102.png 1\n",
      "\n",
      "test103.png 0\n",
      "\n",
      "test104.png 1\n",
      "\n",
      "test106.png 1\n",
      "\n",
      "test107.png 0\n",
      "\n",
      "test108.png 0\n",
      "\n",
      "test111.png 0\n",
      "\n",
      "test113.png 0\n",
      "\n",
      "test114.png 0\n",
      "\n",
      "test117.png 0\n",
      "\n",
      "test118.png 0\n",
      "\n",
      "test119.png 0\n",
      "\n",
      "test120.png 0\n",
      "\n",
      "test121.png 1\n",
      "\n",
      "test123.png 1\n",
      "\n",
      "test124.png 1\n",
      "\n",
      "test125.png 0\n",
      "\n",
      "test126.png 0\n",
      "\n",
      "test127.png 1\n",
      "\n",
      "test128.png 0\n",
      "\n",
      "test129.png 0\n",
      "\n",
      "test131.png 0\n",
      "\n",
      "test132.png 0\n",
      "\n",
      "test133.png 0\n",
      "\n",
      "test134.png 0\n",
      "\n",
      "test135.png 1\n",
      "\n",
      "test136.png 1\n",
      "\n",
      "test137.png 0\n",
      "\n",
      "test138.png 0\n",
      "\n",
      "test139.png 1\n",
      "\n",
      "test140.png 0\n",
      "\n",
      "test141.png 0\n",
      "\n",
      "test142.png 0\n",
      "\n",
      "test143.png 0\n",
      "\n",
      "test144.png 0\n",
      "\n",
      "test146.png 0\n",
      "\n",
      "test149.png 0\n",
      "\n",
      "test150.png 0\n",
      "\n",
      "test151.png 0\n",
      "\n",
      "test152.png 1\n",
      "\n",
      "test153.png 1\n",
      "\n",
      "test154.png 0\n",
      "\n",
      "test155.png 0\n",
      "\n",
      "test156.png 0\n",
      "\n",
      "test157.png 0\n",
      "\n",
      "test158.png 1\n",
      "\n",
      "test159.png 0\n",
      "\n",
      "test160.png 0\n",
      "\n",
      "test163.png 0\n",
      "\n",
      "test164.png 0\n",
      "\n",
      "test165.png 0\n",
      "\n",
      "test166.png 0\n",
      "\n",
      "test167.png 0\n",
      "\n",
      "test168.png 0\n",
      "\n",
      "test169.png 0\n",
      "\n",
      "test170.png 0\n",
      "\n",
      "test171.png 0\n",
      "\n",
      "test172.png 1\n",
      "\n",
      "test173.png 1\n",
      "\n",
      "test175.png 0\n",
      "\n",
      "test176.png 0\n",
      "\n",
      "test177.png 0\n",
      "\n",
      "test179.png 0\n",
      "\n",
      "test180.png 0\n",
      "\n",
      "test181.png 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def natural_sort_key(s):\n",
    "    \"\"\"Key function for natural sorting.\"\"\"\n",
    "    import re\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "output_file_path = 'results.txt'\n",
    "path_to_testset = r'testset'\n",
    "filenames = sorted(os.listdir(path_to_testset), key=natural_sort_key)\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for i, fn in enumerate(filenames):\n",
    "        if fn.split('.')[-1] != 'png':\n",
    "            continue\n",
    "        features = extract_hog_features(cv2.imread(os.path.join(path_to_testset, fn)))\n",
    "        pred = KNN.predict_proba([features])\n",
    "        result = f\"{fn} {np.argmax(pred)}\\n\"\n",
    "        print(result)  \n",
    "        output_file.write(result)\n",
    "    \n",
    "# features=extract_hog_features(cv2.imread('test.png'))\n",
    "# pred=KNN.predict_proba([features])\n",
    "# print(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pkl_file = \"numbers_model.pkl\"  \n",
    "\n",
    "with open(model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(KNN, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
